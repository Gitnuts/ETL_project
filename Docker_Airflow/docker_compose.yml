
version: '3.7'

services:
  postgres:
    image: postgres:9.6
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"

  airflow:
    build: './airflow_docker'
    container_name: airflow_container
    restart: always
    depends_on:
      - postgres
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
    volumes:
      - ./examples/intro-example/dags:/usr/local/airflow/dags
      - ./airflow_docker/requirements.txt:/requirements.txt
      - ./data:/usr/local/airflow/data
      - /Users/artem_lopatenko/.aws:/usr/local/airflow/.aws
      - /Users/artem_lopatenko/.ivy2/cache:/usr/local/airflow/.ivy2/cache
      - /Users/artem_lopatenko/.ivy2/jars:/usr/local/airflow/.ivy2/jars
      # Uncomment to include custom plugins
      # - ./plugins:/usr/local/airflow/plugins
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  zookeeper:                                          # create zookeeper container
    image: wurstmeister/zookeeper
    container_name: zookeeper_container
    ports:
        - "2181:2181"

  kafka:                                              # create an instance of a Kafka broker in a container
    image: wurstmeister/kafka
    container_name: kafka_container
    ports:
        - "9092:9092"                               # expose port
    environment:
        KAFKA_ADVERTISED_HOST_NAME: kafka                               # specify the docker host IP at which other containers can reach the broker
        KAFKA_CREATE_TOPICS: "test:1:1"           # create a 2 topics  with 1 partition and 1 replica
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181                         # specify where the broker can reach Zookeeper
        KAFKA_LISTENERS: PLAINTEXT://kafka:9092                         # the list of addresses on which the Kafka broker will listen on for incoming connections.
        KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092              # Kafka sends the value of this variable to clients during their connection. After receiving that value, the clients use it for sending/consuming records to/from the Kafka broker.y connect to it.
    volumes:
        - /var/run/docker.sock:/var/run/docker.sock

  
  spark:
    image: docker.io/bitnami/spark:3
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8181:8181'
      - '7077:7077'
    volumes:
      - ./examples/intro-example/dags:/usr/local/airflow/dags
  spark-worker:
    image: docker.io/bitnami/spark:3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
